{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HFH - Argument Classifier.ipynb","provenance":[],"toc_visible":true,"collapsed_sections":[],"authorship_tag":"ABX9TyNHDFnM6wKURP2koYvxgPYF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Use of Hugging Face Hub models\n","\n","Created by Andr√©s Segura-Tinoco  \n","Created on Jan 28, 2022"],"metadata":{"id":"F_cCcocgYXDs"}},{"cell_type":"markdown","source":["## <span>1. Argument Classifier</span>"],"metadata":{"id":"NHeeonmFehdf"}},{"cell_type":"code","source":["# !pip install transformers"],"metadata":{"id":"5QXIVeDWcgcJ","executionInfo":{"status":"ok","timestamp":1643657535890,"user_tz":300,"elapsed":3,"user":{"displayName":"Andres Segura Tinoco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4pwzNxRFbjUx6IlQmIuCwf86Ou1pppkb1BnyJ=s64","userId":"03707731297563483663"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from transformers import pipeline"],"metadata":{"id":"d4V8d4m2cc8P","executionInfo":{"status":"ok","timestamp":1643657544776,"user_tz":300,"elapsed":8888,"user":{"displayName":"Andres Segura Tinoco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4pwzNxRFbjUx6IlQmIuCwf86Ou1pppkb1BnyJ=s64","userId":"03707731297563483663"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["task = \"text-classification\"\n","arg_text = \"It has been determined that the amount of greenhouse gases have decreased by almost half because of the prevalence in the utilization of nuclear power.\"\n","non_arg_text = \"I think coding in Google Colab is a lot of fun.\""],"metadata":{"id":"tMXK0OzSdsKV","executionInfo":{"status":"ok","timestamp":1643657544777,"user_tz":300,"elapsed":7,"user":{"displayName":"Andres Segura Tinoco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4pwzNxRFbjUx6IlQmIuCwf86Ou1pppkb1BnyJ=s64","userId":"03707731297563483663"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### 1.1. Model: chkla/roberta-argument\n","https://huggingface.co/chkla/roberta-argument"],"metadata":{"id":"qHO67L1KfCaY"}},{"cell_type":"code","source":["model_name = \"chkla/roberta-argument\"\n","classifier_1 = pipeline(task, model=model_name)"],"metadata":{"id":"vYHcCHTTct7A","executionInfo":{"status":"ok","timestamp":1643657554280,"user_tz":300,"elapsed":9507,"user":{"displayName":"Andres Segura Tinoco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4pwzNxRFbjUx6IlQmIuCwf86Ou1pppkb1BnyJ=s64","userId":"03707731297563483663"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["classifier_1(arg_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DpH9J1vBds6N","executionInfo":{"status":"ok","timestamp":1643657554281,"user_tz":300,"elapsed":13,"user":{"displayName":"Andres Segura Tinoco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4pwzNxRFbjUx6IlQmIuCwf86Ou1pppkb1BnyJ=s64","userId":"03707731297563483663"}},"outputId":"e1284d07-83ee-4d4c-ca9a-816ea0cf1e42"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'label': 'ARGUMENT', 'score': 0.974433183670044}]"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["classifier_1(non_arg_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QggewrcriFmo","executionInfo":{"status":"ok","timestamp":1643657554844,"user_tz":300,"elapsed":574,"user":{"displayName":"Andres Segura Tinoco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4pwzNxRFbjUx6IlQmIuCwf86Ou1pppkb1BnyJ=s64","userId":"03707731297563483663"}},"outputId":"eb76b72f-7fe0-4a16-9bc2-4a20857c851b"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'label': 'NON-ARGUMENT', 'score': 0.9412918090820312}]"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["### 1.2. Model: addy88/argument-classifier\n","https://huggingface.co/addy88/argument-classifier"],"metadata":{"id":"_Os1mD_SfVGW"}},{"cell_type":"code","source":["model_name = \"addy88/argument-classifier\"\n","classifier_2 = pipeline(task, model=model_name)"],"metadata":{"id":"feIrDCuXhApv","executionInfo":{"status":"ok","timestamp":1643657561542,"user_tz":300,"elapsed":6699,"user":{"displayName":"Andres Segura Tinoco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4pwzNxRFbjUx6IlQmIuCwf86Ou1pppkb1BnyJ=s64","userId":"03707731297563483663"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["classifier_2(arg_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fIkxPMhVhKS7","executionInfo":{"status":"ok","timestamp":1643657561543,"user_tz":300,"elapsed":26,"user":{"displayName":"Andres Segura Tinoco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4pwzNxRFbjUx6IlQmIuCwf86Ou1pppkb1BnyJ=s64","userId":"03707731297563483663"}},"outputId":"39169751-03bf-4193-896c-4ba757c1ed7d"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'label': 'ARGUMENT', 'score': 0.974433183670044}]"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["classifier_2(non_arg_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jtuMJd1YiIjj","executionInfo":{"status":"ok","timestamp":1643657561543,"user_tz":300,"elapsed":20,"user":{"displayName":"Andres Segura Tinoco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4pwzNxRFbjUx6IlQmIuCwf86Ou1pppkb1BnyJ=s64","userId":"03707731297563483663"}},"outputId":"18b6712c-77b9-4991-aef7-53570ed13903"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'label': 'NON-ARGUMENT', 'score': 0.9412918090820312}]"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["## <span>2. Classifier from Scratch</span>\n","\n","Using TensorFlow approach"],"metadata":{"id":"Heq0QKapenIE"}},{"cell_type":"code","source":["import tensorflow as tf\n","from transformers import AutoTokenizer\n","from transformers import TFAutoModel\n","from transformers import TFAutoModelForSequenceClassification"],"metadata":{"id":"6awGoSqyepL4","executionInfo":{"status":"ok","timestamp":1643657561544,"user_tz":300,"elapsed":15,"user":{"displayName":"Andres Segura Tinoco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4pwzNxRFbjUx6IlQmIuCwf86Ou1pppkb1BnyJ=s64","userId":"03707731297563483663"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["### 2.1. Preprocessing with a tokenizer"],"metadata":{"id":"mS2nz5vKlmHV"}},{"cell_type":"code","source":["checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)"],"metadata":{"id":"lojRyL89llcT","executionInfo":{"status":"ok","timestamp":1643657564652,"user_tz":300,"elapsed":3122,"user":{"displayName":"Andres Segura Tinoco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4pwzNxRFbjUx6IlQmIuCwf86Ou1pppkb1BnyJ=s64","userId":"03707731297563483663"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["raw_inputs = [\n","    arg_text,\n","    non_arg_text,\n","]\n","inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"tf\")\n","print(inputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WxzILrpVlF8n","executionInfo":{"status":"ok","timestamp":1643657564652,"user_tz":300,"elapsed":11,"user":{"displayName":"Andres Segura Tinoco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4pwzNxRFbjUx6IlQmIuCwf86Ou1pppkb1BnyJ=s64","userId":"03707731297563483663"}},"outputId":"cc798ef7-f684-44cc-8933-1aceed5cff75"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': <tf.Tensor: shape=(2, 28), dtype=int32, numpy=\n","array([[  101,  2009,  2038,  2042,  4340,  2008,  1996,  3815,  1997,\n","        16635, 15865,  2031, 10548,  2011,  2471,  2431,  2138,  1997,\n","         1996, 20272,  1999,  1996, 27891,  1997,  4517,  2373,  1012,\n","          102],\n","       [  101,  1045,  2228, 16861,  1999,  8224, 15270,  2497,  2003,\n","         1037,  2843,  1997,  4569,  1012,   102,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(2, 28), dtype=int32, numpy=\n","array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1],\n","       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0]], dtype=int32)>}\n"]}]},{"cell_type":"markdown","source":["### 2.2. Going through the model"],"metadata":{"id":"VJ0Kbdc7lqDr"}},{"cell_type":"code","source":["model = TFAutoModel.from_pretrained(checkpoint)\n","outputs = model(inputs)\n","print(outputs.last_hidden_state.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zKUpzUF-lqZF","executionInfo":{"status":"ok","timestamp":1643657567666,"user_tz":300,"elapsed":3024,"user":{"displayName":"Andres Segura Tinoco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4pwzNxRFbjUx6IlQmIuCwf86Ou1pppkb1BnyJ=s64","userId":"03707731297563483663"}},"outputId":"a302a6fe-5470-4bee-8e28-3fb7c44e0ac1"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing TFDistilBertModel: ['dropout_19', 'classifier', 'pre_classifier']\n","- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["(2, 28, 768)\n"]}]},{"cell_type":"markdown","source":["### 2.3. Making sense out of numbers"],"metadata":{"id":"BRBmesy2nNEe"}},{"cell_type":"code","source":["model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)\n","outputs = model(inputs)\n","print(outputs.logits.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nsfkOqvjnNYW","executionInfo":{"status":"ok","timestamp":1643657570792,"user_tz":300,"elapsed":3129,"user":{"displayName":"Andres Segura Tinoco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4pwzNxRFbjUx6IlQmIuCwf86Ou1pppkb1BnyJ=s64","userId":"03707731297563483663"}},"outputId":"94e7d0c4-9e2b-45b4-86ee-262ed468b570"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english and are newly initialized: ['dropout_38']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["(2, 2)\n"]}]},{"cell_type":"markdown","source":["### 2.4. Postprocessing the output"],"metadata":{"id":"ON-1W9_boCHM"}},{"cell_type":"code","source":["model.config.id2label"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VKWKvZo4oLLr","executionInfo":{"status":"ok","timestamp":1643657570792,"user_tz":300,"elapsed":19,"user":{"displayName":"Andres Segura Tinoco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4pwzNxRFbjUx6IlQmIuCwf86Ou1pppkb1BnyJ=s64","userId":"03707731297563483663"}},"outputId":"cffda0e3-c9fc-4429-805b-091fbae1f551"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: 'NEGATIVE', 1: 'POSITIVE'}"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["predictions = tf.math.softmax(outputs.logits, axis=-1)\n","print(predictions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KouHW-23oCXy","executionInfo":{"status":"ok","timestamp":1643657570793,"user_tz":300,"elapsed":16,"user":{"displayName":"Andres Segura Tinoco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4pwzNxRFbjUx6IlQmIuCwf86Ou1pppkb1BnyJ=s64","userId":"03707731297563483663"}},"outputId":"4b14a6cf-6767-4bad-a76b-51cd51979ae2"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[9.9009854e-01 9.9014947e-03]\n"," [9.6102111e-04 9.9903905e-01]], shape=(2, 2), dtype=float32)\n"]}]},{"cell_type":"markdown","source":["## <span>3. Tokenization</span>"],"metadata":{"id":"Xxe3d1BRlM1A"}},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"],"metadata":{"id":"zF_gx5hjlOva","executionInfo":{"status":"ok","timestamp":1643657573811,"user_tz":300,"elapsed":3033,"user":{"displayName":"Andres Segura Tinoco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4pwzNxRFbjUx6IlQmIuCwf86Ou1pppkb1BnyJ=s64","userId":"03707731297563483663"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["### 3.1. Encoding\n","\n","Translating text to numbers is known as encoding. Encoding is done in a two-step process: the tokenization, followed by the conversion to input IDs."],"metadata":{"id":"tv6HnwbBl2Zh"}},{"cell_type":"code","source":["tokens = tokenizer.tokenize(non_arg_text)\n","print(tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V25MfzIqnMyX","executionInfo":{"status":"ok","timestamp":1643657573812,"user_tz":300,"elapsed":10,"user":{"displayName":"Andres Segura Tinoco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4pwzNxRFbjUx6IlQmIuCwf86Ou1pppkb1BnyJ=s64","userId":"03707731297563483663"}},"outputId":"804e02bb-0115-4003-f791-1b37f15a1ae2"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["['i', 'think', 'coding', 'in', 'google', 'cola', '##b', 'is', 'a', 'lot', 'of', 'fun', '.']\n"]}]},{"cell_type":"code","source":["ids = tokenizer.convert_tokens_to_ids(tokens)\n","print(ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QBPzFv7Gl2xO","executionInfo":{"status":"ok","timestamp":1643657573812,"user_tz":300,"elapsed":6,"user":{"displayName":"Andres Segura Tinoco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4pwzNxRFbjUx6IlQmIuCwf86Ou1pppkb1BnyJ=s64","userId":"03707731297563483663"}},"outputId":"83bff480-8982-4d04-8fd1-20501c79708f"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["[1045, 2228, 16861, 1999, 8224, 15270, 2497, 2003, 1037, 2843, 1997, 4569, 1012]\n"]}]},{"cell_type":"markdown","source":["### 3.2. Decoding"],"metadata":{"id":"cNOFMFgXl3-_"}},{"cell_type":"code","source":["decoded_string = tokenizer.decode(ids)\n","print(decoded_string)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_9hw2wVrl4Sa","executionInfo":{"status":"ok","timestamp":1643657573812,"user_tz":300,"elapsed":5,"user":{"displayName":"Andres Segura Tinoco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4pwzNxRFbjUx6IlQmIuCwf86Ou1pppkb1BnyJ=s64","userId":"03707731297563483663"}},"outputId":"4f9087b3-19ef-465b-aa87-c887bd10957b"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["i think coding in google colab is a lot of fun.\n"]}]},{"cell_type":"markdown","source":["<hr>\n","\n","**Note**: code taken from the HuggingFace [course](https://huggingface.co/course/).\n","\n","You can contact me on <a href=\"https://twitter.com/SeguraAndres7\" target=\"_blank\">Twitter</a> | <a href=\"https://github.com/ansegura7/\" target=\"_blank\">GitHub</a> | <a href=\"https://www.linkedin.com/in/andres-segura-tinoco/\" target=\"_blank\">LinkedIn</a>"],"metadata":{"id":"n0aSoBYKoiBD"}}]}